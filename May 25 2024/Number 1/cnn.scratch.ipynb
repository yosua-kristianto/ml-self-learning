{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorflow tensorlayerx scikit-learn "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Scratch\n",
    "\n",
    "In endeavor finding the best model that fit for (Multi Label Image Classification Dataset)[https://www.kaggle.com/datasets/meherunnesashraboni/multi-label-image-classification-dataset/data], building CNN model from scratch was made. The work employing Tensorflow's deep learning backend with Tensorlayerx's API.\n",
    "\n",
    "The process to make the model is as follow:\n",
    "\n",
    "1. Dataset Pre-Processing\n",
    "2. Dataset Loading\n",
    "3. Model Architecture\n",
    "4. Training the Model\n",
    "5. Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Dataset Pre-Processing\n",
    "\n",
    "The downloaded dataset structure as follow:\n",
    "\n",
    "1. multilabel_classification.csv\n",
    "2. multilabel_classification(2).csv\n",
    "3. multilabel_classification(6)-reduced_modified.csv\n",
    "4. multilabel_classification(7).csv\n",
    "5. /images\n",
    "\n",
    "During manual exploration, it is found there are 7844 images in total. So it is expected that the csv file, must also consist of only 7844 rows. With this requirement, the `multilabel_classification(6)-reduced_modified.csv` is chosen for its validity. \n",
    "\n",
    "In dataset pre-processing endeavor, the more precise data integrity checks is conducted. This to ensure the registered label within csv file is 1:1 with the image within `/images` folder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas;\n",
    "import os;\n",
    "import pathlib;\n",
    "from tqdm import tqdm;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.colab import drive;\n",
    "# drive.mount('/content/drive');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load csv file\n",
    "dataframe = pandas.read_csv(\"/Users/yosuakristianto/Documents/Dataset Repository/FIN DL/Number 1/multilabel_classification(6)-reduced_modified.csv\");\n",
    "# dataframe = pandas.read_csv(\"D:\\\\tDatase\\\\FIN DL\\\\Number 1\\\\multilabel_classification(6)-reduced_modified.csv\");\n",
    "# dataframe = pandas.read_csv(\"/content/drive/MyDrive/Collab Dataset/FIN DL/Number 1/multilabel_classification(6)-reduced_modified.csv\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Integrity checking initialization\n",
    "image_folder_path = \"/Users/yosuakristianto/Documents/Dataset Repository/FIN DL/Number 1/images/\";\n",
    "# image_folder_path = \"D:\\\\tDatase\\\\FIN DL\\\\Number 1\\\\images\\\\\";\n",
    "# image_folder_path = \"/content/drive/MyDrive/Collab Dataset/FIN DL/Number 1/images/\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data integrity checking - "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7943it [00:01, 5963.77it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((7843, 12), 0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Starts integrity checking\n",
    "print(\"Data integrity checking -\", end = \" \");\n",
    "\n",
    "# Check for image data that not exist in the folder but exist in csv \n",
    "not_found_image = [];\n",
    "\n",
    "for idx, row in tqdm(dataframe.iterrows()):\n",
    "    if(not os.path.exists(path = image_folder_path + row[\"Image_Name\"])):\n",
    "        not_found_image.append(idx);\n",
    "\n",
    "# Check for duplicated image name data in csv\n",
    "dataframe = dataframe.drop_duplicates(subset = [\"Image_Name\"]);\n",
    "\n",
    "dataframe.shape, len(not_found_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Loading\n",
    "\n",
    "With no not found image came from csv file, further steps to do data pre-processing is unnecessary. The step continue to data loading. Data loading part consist of these process below:\n",
    "\n",
    "1. Load image data from disk as NumPy array\n",
    "Why? Because the deep learning model cannot directly read the image file. Instead, image convertion into HWC (Height-Width-Channel) array format, where every channels contains RGB color value. \n",
    "\n",
    "Since the csv and image files are separated entity, sorting image files by its name is conducted for both csv and the image folder during data loading\n",
    "\n",
    "2. Define feature - label for every loaded image data to replace the image name.\n",
    "\n",
    "3. Train-Test-Val splits\n",
    "\n",
    "The splits ratio is 70:30:30\n",
    "\n",
    "4. Data Loading Pattern\n",
    "Making data loading pattern for better batch data segmentation and transformation. This is necessary since the minimum image height is 33 and image width was 120. This can be done by standardizing all images to 224 x 224."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split;\n",
    "import cv2;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7843/7843 [01:04<00:00, 121.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimal size: height: 33 - width: 120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Load image data from disk as NumPy array\n",
    "\n",
    "# Sort image file by name\n",
    "list_files = os.listdir(image_folder_path);\n",
    "list_files.sort()\n",
    "\n",
    "images = [];\n",
    "\n",
    "heights, widths = [], [];\n",
    "\n",
    "for i in tqdm(list_files):\n",
    "    image = cv2.imread(filename = image_folder_path + i);\n",
    "    images.append(image);\n",
    "\n",
    "    height, width, channels = image.shape;\n",
    "\n",
    "    heights.append(height);\n",
    "    widths.append(width);\n",
    "\n",
    "print(f\"Minimal size: height: {min(heights)} - width: {min(widths)}\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7843, (7843, 10))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Defining which is label and which is feature\n",
    "\n",
    "# feature has been declared on the above cell as `images`\n",
    "images = images;\n",
    "\n",
    "# Convert dataframe's content by image name alp\n",
    "sorted_dataframe = dataframe.sort_values(by=[\"Image_Name\"], ascending=[True]);\n",
    "\n",
    "# label\n",
    "labels = sorted_dataframe.drop(columns = [\" Classes(motorcycle, truck, boat, bus, cycle, , , , , , , sitar, ektara, flutes, tabla, harmonium)\", \"Image_Name\"]);\n",
    "\n",
    "(len(images)), labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-Test-Split\n",
    "\n",
    "# First to split it into 70:30\n",
    "train_image, test_image, train_label, test_label = train_test_split(images, labels, train_size = 0.7, test_size = 0.3, random_state = 42); \n",
    "\n",
    "# Since the test is already 30, then to make it 15:15 with val, we need to split it to 50:50\n",
    "test_image, val_image, test_label, val_label = train_test_split(test_image, test_label, train_size = 0.5, test_size = 0.5, random_state = 42);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-29 20:46:48.565465: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Using TensorFlow backend.\n",
      "/Users/yosuakristianto/anaconda3/envs/tlx-tf/lib/python3.12/site-packages/tensorlayerx/__init__.py:45: UserWarning: The version of the backend you have installed does not match the specified backend version and may not work, please install version tensorflow 2.4.0.\n",
      "  warnings.warn(\"The version of the backend you have installed does not match the specified backend version \"\n"
     ]
    }
   ],
   "source": [
    "import tensorlayerx;\n",
    "import numpy;\n",
    "\n",
    "os.environ[\"TL_BACKEND\"] = \"tensorflow\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorlayerx.dataflow import Dataset, DataLoader;\n",
    "from tensorlayerx.vision.transforms import Compose, Normalize, Resize;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "image_standardizer\n",
    "\n",
    "This function helps standardize the image before being load to the model. \n",
    "All images are standardized to 224 x 224. And all pixel values are standardized into -1 to 1. \n",
    "\"\"\"\n",
    "def image_standardizer(image):\n",
    "    transformer = Compose([\n",
    "        Resize(size = (224, 224)),\n",
    "        Normalize(mean=(127.5), std=(127.5), data_format='HWC')\n",
    "    ]);\n",
    "\n",
    "    return transformer(image);\n",
    "\n",
    "# Data Loading Pattern\n",
    "class MainDataset(Dataset):\n",
    "    def __init__(self, image, label):\n",
    "        self.data = image;\n",
    "        # self.label = tensorlayerx.convert_to_tensor(label, dtype = tensorlayerx.float32);\n",
    "        self.label = tensorlayerx.convert_to_tensor(label, dtype = tensorlayerx.float32);\n",
    "\n",
    "    # Take item by index of data\n",
    "    def __getitem__(self, index):\n",
    "        return image_standardizer(self.data[index]), self.label[index];\n",
    "\n",
    "    # Get length of data row\n",
    "    def __len__(self):\n",
    "        return len(self.data);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loading and Transformation\n",
    "train_set = MainDataset(train_image, train_label);\n",
    "test_set = MainDataset(test_image, test_label);\n",
    "val_set = MainDataset(val_image, val_label);\n",
    "\n",
    "# TensorlayerX's Data Loader\n",
    "train_set_loader = DataLoader(train_set, batch_size = 16);\n",
    "test_set_loader = DataLoader(test_set);\n",
    "val_set_loader = DataLoader(val_set);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Architecture\n",
    "\n",
    "This part contains the model architecture within this code. This is where the model being defined. The structure of this part is as follow:\n",
    "\n",
    "1. Model Architecture\n",
    "2. Model Init \n",
    "3. Define Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorlayerx.nn import Module, Conv2d, MaxPool2d, Dropout, Flatten, Linear, Input;\n",
    "from tensorlayerx import LeakyReLU, Softmax;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model architecture\n",
    "class CNNScratch(Module):\n",
    "    def __init__(self):\n",
    "        super(CNNScratch, self).__init__();\n",
    "\n",
    "        self.input = Input(shape = (16, 256, 256));\n",
    "\n",
    "        # Convolutional 1 \n",
    "        self.conv1 = Conv2d(out_channels = 128, kernel_size = (3, 3), stride = (1, 1), act = LeakyReLU, padding = \"SAME\", name = \"conv1\");\n",
    "        self.pool1 = MaxPool2d(kernel_size = (2, 2), name = \"pool1\");\n",
    "\n",
    "        # Convolutional 2\n",
    "        self.conv2 = Conv2d(out_channels = 256, kernel_size = (5, 5), stride = (1, 1), act = LeakyReLU, padding = \"SAME\", name = \"conv2\");\n",
    "        self.pool2 = MaxPool2d(kernel_size = (2, 2), name = \"pool2\");\n",
    "\n",
    "        # Convolutional 3\n",
    "        self.conv3 = Conv2d(out_channels = 128, kernel_size = (3, 3), stride = (1, 1), act = LeakyReLU, padding = \"SAME\", name = \"conv3\");\n",
    "        self.pool3 = MaxPool2d(kernel_size = (3, 3), name = \"pool3\");\n",
    "\n",
    "        # Convolutional 4\n",
    "        self.conv4 = Conv2d(out_channels = 32, kernel_size = (1, 1), stride = (1, 1), act = LeakyReLU, padding = \"SAME\", name = \"conv4\");\n",
    "        self.pool4 = MaxPool2d(kernel_size = (3, 3), name = \"pool4\");\n",
    "\n",
    "        # Fully Connected\n",
    "        self.flat = Flatten(name = \"flat\");\n",
    "\n",
    "        self.do1 = Dropout(p = 0.5, name = \"do1\");\n",
    "\n",
    "        self.linear1 = Linear(out_features = 128, name = \"lin1\"); # Males ngitung in jadi suruh tensorflownya ngitung sendiri aja\n",
    "        self.out = Linear(out_features = 10, in_features = 128, act = Softmax, name = \"out\");\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x);\n",
    "        x = self.pool1(x);\n",
    "        x = self.conv2(x);\n",
    "        x = self.pool2(x);\n",
    "        x = self.conv3(x);\n",
    "        x = self.pool3(x);\n",
    "        x = self.conv4(x);\n",
    "        x = self.pool4(x);\n",
    "\n",
    "        x = self.flat(x);\n",
    "        x = self.do1(x);\n",
    "        x = self.linear1(x);\n",
    "        x = self.out(x);\n",
    "\n",
    "        return x;\n",
    "\n",
    "    def construct(self, x):\n",
    "        x = self.input(x);\n",
    "        \n",
    "        x = self.conv1(x);\n",
    "        x = self.pool1(x);\n",
    "        x = self.conv2(x);\n",
    "        x = self.pool2(x);\n",
    "        x = self.conv3(x);\n",
    "        x = self.pool3(x);\n",
    "        x = self.conv4(x);\n",
    "        x = self.pool4(x);\n",
    "\n",
    "        x = self.flat(x);\n",
    "        x = self.do1(x);\n",
    "        x = self.linear1(x);\n",
    "        x = self.out(x);\n",
    "\n",
    "        return x;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetWithLoss(Module):\n",
    "    \n",
    "    def __init__(self, network: Module, loss_function):\n",
    "        super(NetWithLoss, self).__init__();\n",
    "        self.network = network;\n",
    "        self.loss_fn = loss_function;\n",
    "\n",
    "    def forward(self, data, ground_truth):\n",
    "        prediction = self.network(data);\n",
    "\n",
    "        loss = self.loss_fn(prediction, ground_truth);\n",
    "        return loss;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorlayerx.optimizers import SGD;\n",
    "from tensorlayerx.model import Model, TrainOneStep;\n",
    "from tensorlayerx.losses import sigmoid_cross_entropy, binary_cross_entropy;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training network \n",
      "\n",
      "\n",
      "[TLX] Input  _inputlayer_1: (16, 256, 256)\n",
      "[TLX] Conv2d conv1: out_channels : 128 kernel_size: (3, 3) stride: (1, 1) pad: SAME act: LeakyReLU\n",
      "[TLX] MaxPool2d pool1: kernel_size: (2, 2) stride: (2, 2) padding: SAME return_mask: False\n",
      "[TLX] Conv2d conv2: out_channels : 256 kernel_size: (5, 5) stride: (1, 1) pad: SAME act: LeakyReLU\n",
      "[TLX] MaxPool2d pool2: kernel_size: (2, 2) stride: (2, 2) padding: SAME return_mask: False\n",
      "[TLX] Conv2d conv3: out_channels : 128 kernel_size: (3, 3) stride: (1, 1) pad: SAME act: LeakyReLU\n",
      "[TLX] MaxPool2d pool3: kernel_size: (3, 3) stride: (2, 2) padding: SAME return_mask: False\n",
      "[TLX] Conv2d conv4: out_channels : 32 kernel_size: (1, 1) stride: (1, 1) pad: SAME act: LeakyReLU\n",
      "[TLX] MaxPool2d pool4: kernel_size: (3, 3) stride: (2, 2) padding: SAME return_mask: False\n",
      "[TLX] Flatten flat:\n",
      "[TLX] Dropout do1: p: 0.500000 \n",
      "[TLX] Linear  lin1: 128 No Activation\n",
      "[TLX] Linear  out: 10 Softmax\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "\n",
    "print(\"Start training network \\n\\n\");\n",
    "\n",
    "epoch = 1;\n",
    "network = CNNScratch();\n",
    "# net_W_loss = NetWithLoss(network = network, loss_function = sigmoid_cross_entropy);\n",
    "net_W_loss = NetWithLoss(network = network, loss_function = binary_cross_entropy);\n",
    "\n",
    "trainer = TrainOneStep(net_with_loss = net_W_loss, optimizer = SGD(lr = 1e-3), train_weights = network.trainable_weights);\n",
    "\n",
    "metric_train = tensorlayerx.metrics.Accuracy();\n",
    "metric_val = tensorlayerx.metrics.Accuracy();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1 / 1] -  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/344 [00:00<?, ?it/s]2024-05-29 20:47:21.458579: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: INVALID_ARGUMENT: Expected dimension in the range [-1, 1), but got 1\n",
      "  0%|          | 0/344 [00:25<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[0.09987678 0.09986376 0.09985402 0.10020021 0.09995823 0.09997252\n",
      " 0.09990306 0.10004274 0.10007906 0.10024963], shape=(10,), dtype=float32) [<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 0., 0., 0., 0., 0., 0., 0., 1., 0.], dtype=float32)>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "{{function_node __wrapped__ArgMax_device_/job:localhost/replica:0/task:0/device:CPU:0}} Expected dimension in the range [-1, 1), but got 1 [Op:ArgMax] name: ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 28\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(y_batch)):\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28mprint\u001b[39m(logits[i], [y_batch[i]])\n\u001b[0;32m---> 28\u001b[0m     \u001b[43mmetric_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogits\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_batch\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m;\n\u001b[1;32m     29\u001b[0m     batch_accuracy \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m metric_train\u001b[38;5;241m.\u001b[39mresult();\n\u001b[1;32m     31\u001b[0m train_acc \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m batch_accuracy \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(y_batch);\n",
      "File \u001b[0;32m~/anaconda3/envs/tlx-tf/lib/python3.12/site-packages/tensorlayerx/metrics/tensorflow_metric.py:92\u001b[0m, in \u001b[0;36mAccuracy.update\u001b[0;34m(self, y_pred, y_true)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;124;03mUpdates the internal evaluation result `y_pred` and `y_true`.\u001b[39;00m\n\u001b[1;32m     82\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;124;03m    The ground truth.\u001b[39;00m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtopk \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 92\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccuary\u001b[38;5;241m.\u001b[39mupdate_state(y_true, y_pred)\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/tlx-tf/lib/python3.12/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/anaconda3/envs/tlx-tf/lib/python3.12/site-packages/tensorflow/python/framework/ops.py:5983\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   5981\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mraise_from_not_ok_status\u001b[39m(e, name) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NoReturn:\n\u001b[1;32m   5982\u001b[0m   e\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m name: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m-> 5983\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: {{function_node __wrapped__ArgMax_device_/job:localhost/replica:0/task:0/device:CPU:0}} Expected dimension in the range [-1, 1), but got 1 [Op:ArgMax] name: "
     ]
    }
   ],
   "source": [
    "progress_epoch = [];\n",
    "progress_train_loss = [];\n",
    "progress_train_acc = [];\n",
    "progress_val_loss = [];\n",
    "progress_val_acc = [];\n",
    "\n",
    "for i in range(epoch):\n",
    "\n",
    "    print(f\"Epoch [{i + 1} / {epoch}] - \", end = \" \");\n",
    "\n",
    "    # Training Phase\n",
    "    network.set_train();\n",
    "    train_loss, train_acc, train_n_iter = 0, 0, 0;\n",
    "\n",
    "    for step, (X_batch, y_batch) in enumerate(tqdm(train_set_loader)):\n",
    "        \n",
    "        loss = trainer(X_batch, y_batch);\n",
    "\n",
    "        train_loss += loss;\n",
    "        train_n_iter += 1;\n",
    "\n",
    "        logits = network(X_batch);\n",
    "\n",
    "        batch_accuracy = 0;\n",
    "        # Calculate accuracy\n",
    "        for i in range(len(y_batch)):\n",
    "            print(logits[i], [y_batch[i]])\n",
    "            metric_train.update(logits[i], y_batch[i]);\n",
    "            batch_accuracy += metric_train.result();\n",
    "    \n",
    "        train_acc += batch_accuracy / len(y_batch);\n",
    "\n",
    "     # Validation phase\n",
    "\n",
    "    network.set_eval();\n",
    "    val_loss, val_acc, val_n_iter = 0, 0, 0;\n",
    "\n",
    "    for X_batch, y_batch in enumerate(val_set_loader):\n",
    "        loss = trainer(X_batch, y_batch);\n",
    "        val_loss += loss;\n",
    "\n",
    "        val_n_iter += 1;\n",
    "\n",
    "        logits = network(X_batch);\n",
    "\n",
    "        # Calculate accuracy\n",
    "        metric_val.update(logits, y_batch);\n",
    "        val_acc += metric_val.result();\n",
    "\n",
    "    train_loss = train_loss / train_n_iter;\n",
    "    train_acc = train_acc / train_n_iter;\n",
    "    val_loss = val_loss / val_n_iter;\n",
    "    val_acc = val_acc / val_n_iter;\n",
    "\n",
    "    progress_epoch.append(i+1);\n",
    "    progress_train_acc.append(train_acc);\n",
    "    progress_train_loss.append(train_loss);\n",
    "    progress_val_acc.append(val_acc);\n",
    "    progress_val_loss.append(val_loss);\n",
    "\n",
    "    print(f\"Epoch {i+1} - train loss: {train_loss} - train acc: {train_acc} - val loss: {val_loss} - val acc: {val_acc}\");"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tlx-tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
