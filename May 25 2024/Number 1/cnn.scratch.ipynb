{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorflow tensorlayerx scikit-learn "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Scratch\n",
    "\n",
    "In endeavor finding the best model that fit for (Multi Label Image Classification Dataset)[https://www.kaggle.com/datasets/meherunnesashraboni/multi-label-image-classification-dataset/data], building CNN model from scratch was made. The work employing Tensorflow's deep learning backend with Tensorlayerx's API.\n",
    "\n",
    "The process to make the model is as follow:\n",
    "\n",
    "1. Dataset Pre-Processing\n",
    "2. Dataset Loading\n",
    "3. Model Architecture\n",
    "4. Training the Model\n",
    "5. Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Dataset Pre-Processing\n",
    "\n",
    "The downloaded dataset structure as follow:\n",
    "\n",
    "1. multilabel_classification.csv\n",
    "2. multilabel_classification(2).csv\n",
    "3. multilabel_classification(6)-reduced_modified.csv\n",
    "4. multilabel_classification(7).csv\n",
    "5. /images\n",
    "\n",
    "During manual exploration, it is found there are 7844 images in total. So it is expected that the csv file, must also consist of only 7844 rows. With this requirement, the `multilabel_classification(6)-reduced_modified.csv` is chosen for its validity. \n",
    "\n",
    "In dataset pre-processing endeavor, the more precise data integrity checks is conducted. This to ensure the registered label within csv file is 1:1 with the image within `/images` folder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas;\n",
    "import os;\n",
    "import pathlib;\n",
    "from tqdm import tqdm;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load csv file\n",
    "# dataframe = pandas.read_csv(\"/Users/yosuakristianto/Documents/Dataset Repository/FIN DL/Number 1/multilabel_classification(6)-reduced_modified.csv\");\n",
    "dataframe = pandas.read_csv(\"D:\\\\tDatase\\\\FIN DL\\\\Number 1\\\\multilabel_classification(6)-reduced_modified.csv\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Integrity checking initialization\n",
    "# image_folder_path = \"/Users/yosuakristianto/Documents/Dataset Repository/FIN DL/Number 1/images/\";\n",
    "image_folder_path = \"D:\\\\tDatase\\\\FIN DL\\\\Number 1\\\\images\\\\\";\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data integrity checking - "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7943it [00:00, 10014.42it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((7843, 12), 0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Starts integrity checking\n",
    "print(\"Data integrity checking -\", end = \" \");\n",
    "\n",
    "# Check for image data that not exist in the folder but exist in csv \n",
    "not_found_image = [];\n",
    "\n",
    "for idx, row in tqdm(dataframe.iterrows()):\n",
    "    if(not os.path.exists(path = image_folder_path + row[\"Image_Name\"])):\n",
    "        not_found_image.append(idx);\n",
    "\n",
    "# Check for duplicated image name data in csv\n",
    "dataframe = dataframe.drop_duplicates(subset = [\"Image_Name\"]);\n",
    "\n",
    "dataframe.shape, len(not_found_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Loading\n",
    "\n",
    "With no not found image came from csv file, further steps to do data pre-processing is unnecessary. The step continue to data loading. Data loading part consist of these process below:\n",
    "\n",
    "1. Load image data from disk as NumPy array\n",
    "Why? Because the deep learning model cannot directly read the image file. Instead, image convertion into HWC (Height-Width-Channel) array format, where every channels contains RGB color value. \n",
    "\n",
    "Since the csv and image files are separated entity, sorting image files by its name is conducted for both csv and the image folder during data loading\n",
    "\n",
    "2. Define feature - label for every loaded image data to replace the image name.\n",
    "\n",
    "3. Train-Test-Val splits\n",
    "\n",
    "The splits ratio is 70:30:30\n",
    "\n",
    "4. Data Loading Pattern\n",
    "Making data loading pattern for better batch data segmentation and transformation. This is necessary since the minimum image height is 33 and image width was 120. This can be done by standardizing all images to 224 x 224."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split;\n",
    "import cv2;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7843/7843 [00:39<00:00, 197.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimal size: height: 33 - width: 120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Load image data from disk as NumPy array\n",
    "\n",
    "# Sort image file by name\n",
    "list_files = os.listdir(image_folder_path);\n",
    "list_files.sort()\n",
    "\n",
    "images = [];\n",
    "\n",
    "heights, widths = [], [];\n",
    "\n",
    "for i in tqdm(list_files):\n",
    "    image = cv2.imread(filename = image_folder_path + i);\n",
    "    images.append(image);\n",
    "\n",
    "    height, width, channels = image.shape;\n",
    "\n",
    "    heights.append(height);\n",
    "    widths.append(width);\n",
    "\n",
    "print(f\"Minimal size: height: {min(heights)} - width: {min(widths)}\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7843, (7843, 10))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Defining which is label and which is feature\n",
    "\n",
    "# feature has been declared on the above cell as `images`\n",
    "images = images;\n",
    "\n",
    "# Convert dataframe's content by image name alp\n",
    "sorted_dataframe = dataframe.sort_values(by=[\"Image_Name\"], ascending=[True]);\n",
    "\n",
    "# label\n",
    "labels = sorted_dataframe.drop(columns = [\" Classes(motorcycle, truck, boat, bus, cycle, , , , , , , sitar, ektara, flutes, tabla, harmonium)\", \"Image_Name\"]);\n",
    "\n",
    "(len(images)), labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-Test-Split\n",
    "\n",
    "# First to split it into 70:30\n",
    "train_image, test_image, train_label, test_label = train_test_split(images, labels, train_size = 0.7, test_size = 0.3, random_state = 42); \n",
    "\n",
    "# Since the test is already 30, then to make it 15:15 with val, we need to split it to 50:50\n",
    "test_image, val_image, test_label, val_label = train_test_split(test_image, test_label, train_size = 0.5, test_size = 0.5, random_state = 42);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "c:\\Users\\yosua\\anaconda3\\envs\\tlx-obor\\Lib\\site-packages\\tensorlayerx\\__init__.py:45: UserWarning: The version of the backend you have installed does not match the specified backend version and may not work, please install version tensorflow 2.4.0.\n",
      "  warnings.warn(\"The version of the backend you have installed does not match the specified backend version \"\n"
     ]
    }
   ],
   "source": [
    "import tensorlayerx;\n",
    "import numpy;\n",
    "\n",
    "os.environ[\"TL_BACKEND\"] = \"torch\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorlayerx.dataflow import Dataset, DataLoader;\n",
    "from tensorlayerx.vision.transforms import Compose, Normalize, Resize;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "image_standardizer\n",
    "\n",
    "This function helps standardize the image before being load to the model. \n",
    "All images are standardized to 224 x 224. And all pixel values are standardized into -1 to 1. \n",
    "\"\"\"\n",
    "def image_standardizer(image):\n",
    "    transformer = Compose([\n",
    "        Resize(size = (224, 224)),\n",
    "        Normalize(mean=(127.5), std=(127.5), data_format='HWC')\n",
    "    ]);\n",
    "\n",
    "    return transformer(image);\n",
    "\n",
    "# Data Loading Pattern\n",
    "class MainDataset(Dataset):\n",
    "    def __init__(self, image, label):\n",
    "        self.data = image;\n",
    "        self.label = numpy.array(label).astype('float32');\n",
    "\n",
    "    # Take item by index of data\n",
    "    def __getitem__(self, index):\n",
    "        return image_standardizer(self.data[index]), self.label[index];\n",
    "\n",
    "    # Get length of data row\n",
    "    def __len__(self):\n",
    "        return len(self.data);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loading and Transformation\n",
    "train_set = MainDataset(train_image, train_label);\n",
    "test_set = MainDataset(test_image, test_label);\n",
    "val_set = MainDataset(val_image, val_label);\n",
    "\n",
    "# TensorlayerX's Data Loader\n",
    "train_set_loader = DataLoader(train_set, batch_size = 16);\n",
    "test_set_loader = DataLoader(test_set);\n",
    "val_set_loader = DataLoader(val_set);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Architecture\n",
    "\n",
    "This part contains the model architecture within this code. This is where the model being defined. The structure of this part is as follow:\n",
    "\n",
    "1. Model Architecture\n",
    "2. Model Init \n",
    "3. Define Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorlayerx.nn import Module, Conv2d, MaxPool2d, Dropout, Flatten, Linear, Input;\n",
    "from tensorlayerx import LeakyReLU, Softmax;\n",
    "from tensorlayerx.losses import sigmoid_cross_entropy;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model architecture\n",
    "class CNNScratch(Module):\n",
    "    def __init__(self):\n",
    "        super(CNNScratch, self).__init__();\n",
    "\n",
    "        self.input = Input(shape = (16, 256, 256));\n",
    "\n",
    "        # Convolutional 1 \n",
    "        self.conv1 = Conv2d(out_channels = 128, kernel_size = (3, 3), stride = (1, 1), act = LeakyReLU, padding = \"SAME\", name = \"conv1\");\n",
    "        self.pool1 = MaxPool2d(kernel_size = (2, 2), name = \"pool1\");\n",
    "\n",
    "        # Convolutional 2\n",
    "        self.conv2 = Conv2d(out_channels = 256, kernel_size = (5, 5), stride = (1, 1), act = LeakyReLU, padding = \"SAME\", name = \"conv2\");\n",
    "        self.pool2 = MaxPool2d(kernel_size = (2, 2), name = \"pool2\");\n",
    "\n",
    "        # Convolutional 3\n",
    "        self.conv3 = Conv2d(out_channels = 128, kernel_size = (3, 3), stride = (1, 1), act = LeakyReLU, padding = \"SAME\", name = \"conv3\");\n",
    "        self.pool3 = MaxPool2d(kernel_size = (3, 3), name = \"pool3\");\n",
    "\n",
    "        # Convolutional 4\n",
    "        self.conv4 = Conv2d(out_channels = 32, kernel_size = (1, 1), stride = (1, 1), act = LeakyReLU, padding = \"SAME\", name = \"conv4\");\n",
    "        self.pool4 = MaxPool2d(kernel_size = (3, 3), name = \"pool4\");\n",
    "\n",
    "        # Fully Connected\n",
    "        self.flat = Flatten(name = \"flat\");\n",
    "\n",
    "        self.do1 = Dropout(p = 0.5, name = \"do1\");\n",
    "\n",
    "        self.linear1 = Linear(out_features = 128, name = \"lin1\"); # Males ngitung in jadi suruh tensorflownya ngitung sendiri aja\n",
    "        self.out = Linear(out_features = 10, in_features = 128, act = Softmax, name = \"out\");\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x);\n",
    "        x = self.pool1(x);\n",
    "        x = self.conv2(x);\n",
    "        x = self.pool2(x);\n",
    "        x = self.conv3(x);\n",
    "        x = self.pool3(x);\n",
    "        x = self.conv4(x);\n",
    "        x = self.pool4(x);\n",
    "\n",
    "        x = self.flat(x);\n",
    "        x = self.do1(x);\n",
    "        x = self.linear1(x);\n",
    "        x = self.out(x);\n",
    "\n",
    "        return x;\n",
    "\n",
    "    def construct(self, x):\n",
    "        x = self.input(x);\n",
    "        \n",
    "        x = self.conv1(x);\n",
    "        x = self.pool1(x);\n",
    "        x = self.conv2(x);\n",
    "        x = self.pool2(x);\n",
    "        x = self.conv3(x);\n",
    "        x = self.pool3(x);\n",
    "        x = self.conv4(x);\n",
    "        x = self.pool4(x);\n",
    "\n",
    "        x = self.flat(x);\n",
    "        x = self.do1(x);\n",
    "        x = self.linear1(x);\n",
    "        x = self.out(x);\n",
    "\n",
    "        return x;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetWithLoss(Module):\n",
    "    \n",
    "    def __init__(self, network: Module, loss_function):\n",
    "        super(NetWithLoss, self).__init__();\n",
    "        self.network = network;\n",
    "        self.loss_fn = loss_function;\n",
    "\n",
    "    def forward(self, data, ground_truth):\n",
    "        prediction = self.network(data);\n",
    "\n",
    "        loss = self.loss_fn(prediction, ground_truth);\n",
    "        return loss;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorlayerx.optimizers import SGD;\n",
    "from tensorlayerx.model import Model, TrainOneStep;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training network \n",
      "\n",
      "\n",
      "[TLX] Input  _inputlayer_1: (16, 256, 256)\n",
      "[TLX] Conv2d conv1: out_channels : 128 kernel_size: (3, 3) stride: (1, 1) pad: SAME act: LeakyReLU\n",
      "[TLX] MaxPool2d pool1: kernel_size: (2, 2) stride: (2, 2) padding: SAME return_mask: False\n",
      "[TLX] Conv2d conv2: out_channels : 256 kernel_size: (5, 5) stride: (1, 1) pad: SAME act: LeakyReLU\n",
      "[TLX] MaxPool2d pool2: kernel_size: (2, 2) stride: (2, 2) padding: SAME return_mask: False\n",
      "[TLX] Conv2d conv3: out_channels : 128 kernel_size: (3, 3) stride: (1, 1) pad: SAME act: LeakyReLU\n",
      "[TLX] MaxPool2d pool3: kernel_size: (3, 3) stride: (2, 2) padding: SAME return_mask: False\n",
      "[TLX] Conv2d conv4: out_channels : 32 kernel_size: (1, 1) stride: (1, 1) pad: SAME act: LeakyReLU\n",
      "[TLX] MaxPool2d pool4: kernel_size: (3, 3) stride: (2, 2) padding: SAME return_mask: False\n",
      "[TLX] Flatten flat:\n",
      "[TLX] Dropout do1: p: 0.500000 \n",
      "[TLX] Linear  lin1: 128 No Activation\n",
      "[TLX] Linear  out: 10 Softmax\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "\n",
    "print(\"Start training network \\n\\n\");\n",
    "\n",
    "epoch = 1;\n",
    "network = CNNScratch();\n",
    "net_W_loss = NetWithLoss(network = network, loss_function = sigmoid_cross_entropy);\n",
    "\n",
    "trainer = TrainOneStep(net_with_loss = net_W_loss, optimizer = SGD(lr = 1e-3), train_weights = network.trainable_weights);\n",
    "\n",
    "metric_train = tensorlayerx.metrics.Accuracy();\n",
    "metric_val = tensorlayerx.metrics.Accuracy();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1 / 1] -  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/344 [00:00<?, ?it/s]"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "progress_epoch = [];\n",
    "progress_train_loss = [];\n",
    "progress_train_acc = [];\n",
    "progress_val_loss = [];\n",
    "progress_val_acc = [];\n",
    "\n",
    "for i in range(epoch):\n",
    "\n",
    "    print(f\"Epoch [{i + 1} / {epoch}] - \", end = \" \");\n",
    "\n",
    "    # Training Phase\n",
    "    network.set_train();\n",
    "    train_loss, train_acc, train_n_iter = 0, 0, 0;\n",
    "\n",
    "    for step, (X_batch, y_batch) in enumerate(tqdm(train_set_loader)):\n",
    "        \n",
    "        # Batch training\n",
    "        for i in range(len(X_batch)):\n",
    "            loss = trainer(X_batch, y_batch);\n",
    "            train_loss += loss;\n",
    "\n",
    "            train_n_iter += 1;\n",
    "\n",
    "            logits = network(X_batch[i]);\n",
    "\n",
    "            # Calculate accuracy\n",
    "            metric_train.update(logits, y_batch);\n",
    "            train_acc += metric_train.result();\n",
    "\n",
    "     # Validation phase\n",
    "\n",
    "    network.set_eval();\n",
    "    val_loss, val_acc, val_n_iter = 0, 0, 0;\n",
    "\n",
    "    for X_batch, y_batch in enumerate(val_set_loader):\n",
    "        loss = trainer(X_batch, y_batch);\n",
    "        val_loss += loss;\n",
    "\n",
    "        val_n_iter += 1;\n",
    "\n",
    "        logits = network(X_batch);\n",
    "\n",
    "        # Calculate accuracy\n",
    "        metric_val.update(logits, y_batch);\n",
    "        val_acc += metric_val.result();\n",
    "\n",
    "    train_loss = train_loss / train_n_iter;\n",
    "    train_acc = train_acc / train_n_iter;\n",
    "    val_loss = val_loss / val_n_iter;\n",
    "    val_acc = val_acc / val_n_iter;\n",
    "\n",
    "    progress_epoch.append(i+1);\n",
    "    progress_train_acc.append(train_acc);\n",
    "    progress_train_loss.append(train_loss);\n",
    "    progress_val_acc.append(val_acc);\n",
    "    progress_val_loss.append(val_loss);\n",
    "\n",
    "    print(f\"Epoch {i+1} - train loss: {train_loss} - train acc: {train_acc} - val loss: {val_loss} - val acc: {val_acc}\");"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tlx-tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
