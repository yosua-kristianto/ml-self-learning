{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorflow tensorlayerx scikit-learn "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Scratch\n",
    "\n",
    "In endeavor finding the best model that fit for (Multi Label Image Classification Dataset)[https://www.kaggle.com/datasets/meherunnesashraboni/multi-label-image-classification-dataset/data], building CNN model from scratch was made. The work employing Tensorflow's deep learning backend with Tensorlayerx's API.\n",
    "\n",
    "The process to make the model is as follow:\n",
    "\n",
    "1. Dataset Pre-Processing\n",
    "2. Dataset Loading\n",
    "3. Model Architecture\n",
    "4. Training the Model\n",
    "5. Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Dataset Pre-Processing\n",
    "\n",
    "The downloaded dataset structure as follow:\n",
    "\n",
    "1. multilabel_classification.csv\n",
    "2. multilabel_classification(2).csv\n",
    "3. multilabel_classification(6)-reduced_modified.csv\n",
    "4. multilabel_classification(7).csv\n",
    "5. /images\n",
    "\n",
    "During manual exploration, it is found there are 7844 images in total. So it is expected that the csv file, must also consist of only 7844 rows. With this requirement, the `multilabel_classification(6)-reduced_modified.csv` is chosen for its validity. \n",
    "\n",
    "In dataset pre-processing endeavor, the more precise data integrity checks is conducted. This to ensure the registered label within csv file is 1:1 with the image within `/images` folder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas;\n",
    "import os;\n",
    "import pathlib;\n",
    "from tqdm import tqdm;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load csv file\n",
    "dataframe = pandas.read_csv(\"/Users/yosuakristianto/Documents/Dataset Repository/FIN DL/Number 1/multilabel_classification(6)-reduced_modified.csv\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Integrity checking initialization\n",
    "image_folder_path = \"/Users/yosuakristianto/Documents/Dataset Repository/FIN DL/Number 1/images/\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data integrity checking - "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7943it [00:01, 4887.57it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((7843, 12), 0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Starts integrity checking\n",
    "print(\"Data integrity checking -\", end = \" \");\n",
    "\n",
    "# Check for image data that not exist in the folder but exist in csv \n",
    "not_found_image = [];\n",
    "\n",
    "for idx, row in tqdm(dataframe.iterrows()):\n",
    "    if(not os.path.exists(path = image_folder_path + row[\"Image_Name\"])):\n",
    "        not_found_image.append(idx);\n",
    "\n",
    "# Check for duplicated image name data in csv\n",
    "dataframe = dataframe.drop_duplicates(subset = [\"Image_Name\"]);\n",
    "\n",
    "dataframe.shape, len(not_found_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Loading\n",
    "\n",
    "With no not found image came from csv file, further steps to do data pre-processing is unnecessary. The step continue to data loading. Data loading part consist of these process below:\n",
    "\n",
    "1. Load image data from disk as NumPy array\n",
    "Why? Because the deep learning model cannot directly read the image file. Instead, image convertion into HWC (Height-Width-Channel) array format, where every channels contains RGB color value. \n",
    "\n",
    "Since the csv and image files are separated entity, sorting image files by its name is conducted for both csv and the image folder during data loading\n",
    "\n",
    "2. Define feature - label for every loaded image data to replace the image name.\n",
    "\n",
    "3. Train-Test-Val splits\n",
    "\n",
    "The splits ratio is 70:30:30\n",
    "\n",
    "4. Data Loading Pattern\n",
    "Making data loading pattern for better batch data segmentation and transformation. This is necessary since the minimum image height is 33 and image width was 120. This can be done by standardizing all images to 224 x 224."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split;\n",
    "import cv2;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7843/7843 [01:35<00:00, 82.03it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimal size: height: 33 - width: 120\n"
     ]
    }
   ],
   "source": [
    "# Load image data from disk as NumPy array\n",
    "\n",
    "# Sort image file by name\n",
    "list_files = os.listdir(image_folder_path);\n",
    "list_files.sort()\n",
    "\n",
    "images = [];\n",
    "\n",
    "heights, widths = [], [];\n",
    "\n",
    "for i in tqdm(list_files):\n",
    "    image = cv2.imread(filename = image_folder_path + i);\n",
    "    images.append(image);\n",
    "\n",
    "    height, width, channels = image.shape;\n",
    "\n",
    "    heights.append(height);\n",
    "    widths.append(width);\n",
    "\n",
    "print(f\"Minimal size: height: {min(heights)} - width: {min(widths)}\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7843, (7843, 10))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Defining which is label and which is feature\n",
    "\n",
    "# feature has been declared on the above cell as `images`\n",
    "images = images;\n",
    "\n",
    "# Convert dataframe's content by image name alp\n",
    "sorted_dataframe = dataframe.sort_values(by=[\"Image_Name\"], ascending=[True]);\n",
    "\n",
    "# label\n",
    "labels = sorted_dataframe.drop(columns = [\" Classes(motorcycle, truck, boat, bus, cycle, , , , , , , sitar, ektara, flutes, tabla, harmonium)\", \"Image_Name\"]);\n",
    "\n",
    "(len(images)), labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-Test-Split\n",
    "\n",
    "# First to split it into 70:30\n",
    "train_image, test_image, train_label, test_label = train_test_split(images, labels, train_size = 0.7, test_size = 0.3, random_state = 42); \n",
    "\n",
    "# Since the test is already 30, then to make it 15:15 with val, we need to split it to 50:50\n",
    "test_image, val_image, test_label, val_label = train_test_split(test_image, test_label, train_size = 0.5, test_size = 0.5, random_state = 42);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-27 16:52:07.878172: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Using TensorFlow backend.\n",
      "/Users/yosuakristianto/anaconda3/envs/tlx-tf/lib/python3.12/site-packages/tensorlayerx/__init__.py:45: UserWarning: The version of the backend you have installed does not match the specified backend version and may not work, please install version tensorflow 2.4.0.\n",
      "  warnings.warn(\"The version of the backend you have installed does not match the specified backend version \"\n"
     ]
    }
   ],
   "source": [
    "import tensorlayerx;\n",
    "import numpy;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorlayerx.dataflow import Dataset, DataLoader;\n",
    "from tensorlayerx.vision.transforms import Compose, Normalize, Resize;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Loading Pattern\n",
    "class DatasetLoader(Dataset):\n",
    "    def __init__(self, image, label):\n",
    "        self.data = image;\n",
    "        self.label = label.astype('float32');\n",
    "\n",
    "    \"\"\"\n",
    "    image_standardizer\n",
    "\n",
    "    This function helps standardize the image before being load to the model. \n",
    "    All images are standardized to 224 x 224. And all pixel values are standardized into -1 to 1. \n",
    "    \"\"\"\n",
    "    def image_standardizer(self, image):\n",
    "        transformer = Compose([\n",
    "            Resize(size = (224, 224)),\n",
    "            Normalize(mean=(127.5), std=(127.5), data_format='HWC')\n",
    "        ]);\n",
    "\n",
    "        return transformer(image);\n",
    "\n",
    "    # Take item by index of data\n",
    "    def __getitem__(self, index):\n",
    "        return self.image_standardizer(self.data[index]), self.label[index];\n",
    "\n",
    "    # Get length of data row\n",
    "    def __len__(self):\n",
    "        return len(self.data);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'astype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Data loading and Transformation\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m train_set \u001b[38;5;241m=\u001b[39m \u001b[43mDatasetLoader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_image\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_label\u001b[49m\u001b[43m)\u001b[49m;\n\u001b[1;32m      3\u001b[0m test_set \u001b[38;5;241m=\u001b[39m DatasetLoader(test_image, test_label);\n\u001b[1;32m      4\u001b[0m val_set \u001b[38;5;241m=\u001b[39m DatasetLoader(val_image, val_label);\n",
      "Cell \u001b[0;32mIn[12], line 4\u001b[0m, in \u001b[0;36mDatasetLoader.__init__\u001b[0;34m(self, image, label)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, image, label):\n\u001b[0;32m----> 4\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m \u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m'\u001b[39m);\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabel \u001b[38;5;241m=\u001b[39m label\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'astype'"
     ]
    }
   ],
   "source": [
    "# Data loading and Transformation\n",
    "train_set = DatasetLoader(train_image, train_label);\n",
    "test_set = DatasetLoader(test_image, test_label);\n",
    "val_set = DatasetLoader(val_image, val_label);\n",
    "\n",
    "# TensorlayerX's Data Loader\n",
    "train_set = DataLoader(train_set, batch_size = 16);\n",
    "test_set = DataLoader(test_set);\n",
    "val_set = DataLoader(val_set);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataLoader.__len__ of <tensorlayerx.dataflow.dataloader.DataLoader object at 0x147cb3710>>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.__len__()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Architecture\n",
    "\n",
    "This part contains the model architecture within this code. This is where the model being defined. The structure of this part is as follow:\n",
    "\n",
    "1. Model Architecture\n",
    "2. Model Init \n",
    "3. Define Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorlayerx.nn import Module, Conv2d, MaxPool2d, Dropout, Flatten, Linear, Input;\n",
    "from tensorlayerx import LeakyReLU, Softmax;\n",
    "from tensorlayerx.losses import sigmoid_cross_entropy;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model architecture\n",
    "class CNNScratch(Module):\n",
    "    def __init__(self):\n",
    "        super(CNNScratch, self).__init__();\n",
    "\n",
    "        self.input = Input(shape = (16, 256, 256));\n",
    "\n",
    "        # Convolutional 1 \n",
    "        self.conv1 = Conv2d(out_channels = 128, kernel_size = (3, 3), stride = (1, 1), act = LeakyReLU, padding = \"SAME\", name = \"conv1\");\n",
    "        self.pool1 = MaxPool2d(kernel_size = (2, 2), name = \"pool1\");\n",
    "\n",
    "        # Convolutional 2\n",
    "        self.conv2 = Conv2d(out_channels = 256, kernel_size = (5, 5), stride = (1, 1), act = LeakyReLU, padding = \"SAME\", name = \"conv2\");\n",
    "        self.pool2 = MaxPool2d(kernel_size = (2, 2), name = \"pool2\");\n",
    "\n",
    "        # Convolutional 3\n",
    "        self.conv3 = Conv2d(out_channels = 128, kernel_size = (3, 3), stride = (1, 1), act = LeakyReLU, padding = \"SAME\", name = \"conv3\");\n",
    "        self.pool3 = MaxPool2d(kernel_size = (3, 3), name = \"pool3\");\n",
    "\n",
    "        # Convolutional 4\n",
    "        self.conv4 = Conv2d(out_channels = 32, kernel_size = (1, 1), stride = (1, 1), act = LeakyReLU, padding = \"SAME\", name = \"conv4\");\n",
    "        self.pool4 = MaxPool2d(kernel_size = (3, 3), name = \"pool4\");\n",
    "\n",
    "        # Fully Connected\n",
    "        self.flat = Flatten(name = \"flat\");\n",
    "\n",
    "        self.do1 = Dropout(p = 0.5, name = \"do1\");\n",
    "\n",
    "        self.linear1 = Linear(out_features = 128, name = \"lin1\"); # Males ngitung in jadi suruh tensorflownya ngitung sendiri aja\n",
    "        self.out = Linear(out_features = 10, in_features = 128, name = \"out\");\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x);\n",
    "        x = self.pool1(x);\n",
    "        x = self.conv2(x);\n",
    "        x = self.pool2(x);\n",
    "        x = self.conv3(x);\n",
    "        x = self.pool3(x);\n",
    "        x = self.conv4(x);\n",
    "        x = self.pool4(x);\n",
    "\n",
    "        x = self.flat(x);\n",
    "        x = self.do1(x);\n",
    "        x = self.linear1(x);\n",
    "        x = self.out(x);\n",
    "\n",
    "        return x;\n",
    "\n",
    "    def construct(self, x):\n",
    "        x = self.input(x);\n",
    "        \n",
    "        x = self.conv1(x);\n",
    "        x = self.pool1(x);\n",
    "        x = self.conv2(x);\n",
    "        x = self.pool2(x);\n",
    "        x = self.conv3(x);\n",
    "        x = self.pool3(x);\n",
    "        x = self.conv4(x);\n",
    "        x = self.pool4(x);\n",
    "\n",
    "        x = self.flat(x);\n",
    "        x = self.do1(x);\n",
    "        x = self.linear1(x);\n",
    "        x = self.out(x);\n",
    "\n",
    "        return x;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetWithLoss(Module):\n",
    "    \n",
    "    def __init__(self, network: Module, loss_function):\n",
    "        super(NetWithLoss, self).__init__();\n",
    "        self.network = network;\n",
    "        self.loss_fn = loss_function;\n",
    "\n",
    "    def forward(self, data, ground_truth):\n",
    "        prediction = self.network(data);\n",
    "\n",
    "        loss = self.loss_fn(predictions, ground_truth);\n",
    "        return loss;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorlayerx.optimizers import SGD;\n",
    "from tensorlayerx.model import Model, TrainOneStep;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training network \n",
      "\n",
      "\n",
      "[TLX] Input  _inputlayer_1: (16, 256, 256)\n",
      "[TLX] Conv2d conv1: out_channels : 128 kernel_size: (3, 3) stride: (1, 1) pad: SAME act: LeakyReLU\n",
      "[TLX] MaxPool2d pool1: kernel_size: (2, 2) stride: (2, 2) padding: SAME return_mask: False\n",
      "[TLX] Conv2d conv2: out_channels : 256 kernel_size: (5, 5) stride: (1, 1) pad: SAME act: LeakyReLU\n",
      "[TLX] MaxPool2d pool2: kernel_size: (2, 2) stride: (2, 2) padding: SAME return_mask: False\n",
      "[TLX] Conv2d conv3: out_channels : 128 kernel_size: (3, 3) stride: (1, 1) pad: SAME act: LeakyReLU\n",
      "[TLX] MaxPool2d pool3: kernel_size: (3, 3) stride: (2, 2) padding: SAME return_mask: False\n",
      "[TLX] Conv2d conv4: out_channels : 32 kernel_size: (1, 1) stride: (1, 1) pad: SAME act: LeakyReLU\n",
      "[TLX] MaxPool2d pool4: kernel_size: (3, 3) stride: (2, 2) padding: SAME return_mask: False\n",
      "[TLX] Flatten flat:\n",
      "[TLX] Dropout do1: p: 0.500000 \n",
      "[TLX] Linear  lin1: 128 No Activation\n",
      "[TLX] Linear  out: 10 No Activation\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "\n",
    "print(\"Start training network \\n\\n\");\n",
    "\n",
    "epoch = 1;\n",
    "network = CNNScratch();\n",
    "net_W_loss = NetWithLoss(network = network, loss_function = sigmoid_cross_entropy);\n",
    "\n",
    "trainer = TrainOneStep(net_with_loss = net_W_loss, optimizer = SGD(lr = 1e-3), train_weights = network.trainable_weights);\n",
    "\n",
    "metric_train = tensorlayerx.metrics.Accuracy();\n",
    "metric_val = tensorlayerx.metrics.Accuracy();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1 / 1] -  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/344 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/tlx-tf/lib/python3.12/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 0",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[81], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m network\u001b[38;5;241m.\u001b[39mset_train();\n\u001b[1;32m     13\u001b[0m train_loss, train_acc, train_n_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m;\n\u001b[0;32m---> 15\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mX_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_batch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_batch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m;\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_loss\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m;\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/tlx-tf/lib/python3.12/site-packages/tqdm/std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1181\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   1182\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[1;32m   1183\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[1;32m   1184\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/tlx-tf/lib/python3.12/site-packages/tensorlayerx/dataflow/utils.py:417\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    415\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    416\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()\n\u001b[0;32m--> 417\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    418\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    419\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/anaconda3/envs/tlx-tf/lib/python3.12/site-packages/tensorlayerx/dataflow/utils.py:438\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    436\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    437\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()\n\u001b[0;32m--> 438\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    439\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/anaconda3/envs/tlx-tf/lib/python3.12/site-packages/tensorlayerx/dataflow/utils.py:347\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, batch_indices)\u001b[0m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch_indices):\n\u001b[1;32m    346\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_batch:\n\u001b[0;32m--> 347\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mid\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28mid\u001b[39m \u001b[38;5;129;01min\u001b[39;00m batch_indices]\n\u001b[1;32m    348\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    349\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[batch_indices]\n",
      "Cell \u001b[0;32mIn[66], line 22\u001b[0m, in \u001b[0;36mDatasetLoader.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, index):\n\u001b[0;32m---> 22\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage_standardizer(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata[index]), \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/tlx-tf/lib/python3.12/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/anaconda3/envs/tlx-tf/lib/python3.12/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "progress_epoch = [];\n",
    "progress_train_loss = [];\n",
    "progress_train_acc = [];\n",
    "progress_val_loss = [];\n",
    "progress_val_acc = [];\n",
    "\n",
    "for i in range(epoch):\n",
    "\n",
    "    print(f\"Epoch [{i + 1} / {epoch}] - \", end = \" \");\n",
    "\n",
    "    # Training Phase\n",
    "    network.set_train();\n",
    "    train_loss, train_acc, train_n_iter = 0, 0, 0;\n",
    "\n",
    "    for X_batch, y_batch in tqdm(train_set):\n",
    "        loss = trainer(X_batch, y_batch);\n",
    "        train_loss += loss;\n",
    "\n",
    "        train_n_iter += 1;\n",
    "\n",
    "        logits = network(X_batch);\n",
    "\n",
    "        # Calculate accuracy\n",
    "        metric_train.update(logits, y_batch);\n",
    "        train_acc += metric_train.result();\n",
    "\n",
    "     # Validation phase\n",
    "\n",
    "    network.set_eval();\n",
    "    val_loss, val_acc, val_n_iter = 0, 0, 0;\n",
    "\n",
    "    for X_batch, y_batch in val_set:\n",
    "        loss = trainer(X_batch, y_batch);\n",
    "        val_loss += loss;\n",
    "\n",
    "        val_n_iter += 1;\n",
    "\n",
    "        logits = network(X_batch);\n",
    "\n",
    "        # Calculate accuracy\n",
    "        metric_val.update(logits, y_batch);\n",
    "        val_acc += metric_val.result();\n",
    "\n",
    "    train_loss = train_loss / train_n_iter;\n",
    "    train_acc = train_acc / train_n_iter;\n",
    "    val_loss = val_loss / val_n_iter;\n",
    "    val_acc = val_acc / val_n_iter;\n",
    "\n",
    "    progress_epoch.append(i+1);\n",
    "    progress_train_acc.append(train_acc);\n",
    "    progress_train_loss.append(train_loss);\n",
    "    progress_val_acc.append(val_acc);\n",
    "    progress_val_loss.append(val_loss);\n",
    "\n",
    "    print(f\"Epoch {i+1} - {time_done}s - train loss: {train_loss} - train acc: {train_acc} - val loss: {val_loss} - val acc: {val_acc}\");"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tlx-tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
