{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Number 4\n",
    "4.\tAnda diberikan sebuah dataset tentang data kelulusan mahasiswa yang dapat diambil pada link .... . Jika diperhatikan dataset ini adalah dataset yang imbalance.\n",
    "a. [5%] Berikan Solusi terhadap data imbalaced yang ditemui\n",
    "b. [10%] Gunakan model klasifikasi Decision Tree untuk data tersebut\n",
    "c. [5%] Lakukan evaluasi performa model klasifikasi yang dibangun\n",
    "\n",
    "Before proceeding to solve the problem, I basically taking a look at the data wise. The data is barely balanced. Not just the label tho'. The feature are also seems to be, imbalanced. Especially when it comes to the ordinal / categorical data. So what I planning is:\n",
    "\n",
    "1. Data Pre-Processing\n",
    "- Drop \"NAMA\" column since it is not really matters.\n",
    "- Drop any row that contains NaN or null data. \n",
    "- Perform Hot-Top Encoding to \"JENIS KELAMIN\", \"STATUS MAHASISWA\", \"STATUS NIKAH\".\n",
    "- Convert \"STATUS KELULUSAN\", so that \"TEPAT\" converted to 1, otherwise goes 0.\n",
    "\n",
    "2. \"Fixing\" the Imbalance problem\n",
    "- Perform the impossible by oversampling the data label\n",
    "- Perform data normalization by performing data scaler to all features.\n",
    "\n",
    "3. Training Preparation\n",
    "- Train-Test Split\n",
    "\n",
    "4. Model Fitting\n",
    "- Parameter Searches\n",
    "- Model Fitting\n",
    "\n",
    "5. Model Evaluation\n",
    "- Moddel Evaluation with Accuracy and ROC AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas;\n",
    "from imblearn.over_sampling import SMOTE;\n",
    "from sklearn.preprocessing import StandardScaler;\n",
    "from sklearn.model_selection import train_test_split;\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier;\n",
    "from sklearn.model_selection import GridSearchCV;\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration Part\n",
    "\n",
    "Basically just head the code out to show the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NAMA</th>\n",
       "      <th>JENIS KELAMIN</th>\n",
       "      <th>STATUS MAHASISWA</th>\n",
       "      <th>UMUR</th>\n",
       "      <th>STATUS NIKAH</th>\n",
       "      <th>IPS 1</th>\n",
       "      <th>IPS 2</th>\n",
       "      <th>IPS 3</th>\n",
       "      <th>IPS 4</th>\n",
       "      <th>IPS 5</th>\n",
       "      <th>IPS 6</th>\n",
       "      <th>IPS 7</th>\n",
       "      <th>IPS 8</th>\n",
       "      <th>IPK</th>\n",
       "      <th>STATUS KELULUSAN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UNAMA</td>\n",
       "      <td>LAKI - LAKI</td>\n",
       "      <td>MAHASISWA</td>\n",
       "      <td>24</td>\n",
       "      <td>BELUM MENIKAH</td>\n",
       "      <td>3.17</td>\n",
       "      <td>2.70</td>\n",
       "      <td>3.23</td>\n",
       "      <td>2.41</td>\n",
       "      <td>3.00</td>\n",
       "      <td>2.47</td>\n",
       "      <td>1.75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.75</td>\n",
       "      <td>TEPAT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LEYLA TRIYANA PRATIWI</td>\n",
       "      <td>PEREMPUAN</td>\n",
       "      <td>MAHASISWA</td>\n",
       "      <td>26</td>\n",
       "      <td>BELUM MENIKAH</td>\n",
       "      <td>3.60</td>\n",
       "      <td>3.50</td>\n",
       "      <td>3.42</td>\n",
       "      <td>2.85</td>\n",
       "      <td>3.31</td>\n",
       "      <td>2.95</td>\n",
       "      <td>2.18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.39</td>\n",
       "      <td>TEPAT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>VERIS SOFIYAN PRAYOGA</td>\n",
       "      <td>LAKI - LAKI</td>\n",
       "      <td>MAHASISWA</td>\n",
       "      <td>29</td>\n",
       "      <td>BELUM MENIKAH</td>\n",
       "      <td>2.67</td>\n",
       "      <td>2.66</td>\n",
       "      <td>2.93</td>\n",
       "      <td>3.14</td>\n",
       "      <td>2.92</td>\n",
       "      <td>2.64</td>\n",
       "      <td>2.88</td>\n",
       "      <td>0.50</td>\n",
       "      <td>2.81</td>\n",
       "      <td>TEPAT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ADITYA AKBAR NUGRAHA</td>\n",
       "      <td>LAKI - LAKI</td>\n",
       "      <td>MAHASISWA</td>\n",
       "      <td>27</td>\n",
       "      <td>BELUM MENIKAH</td>\n",
       "      <td>2.48</td>\n",
       "      <td>2.86</td>\n",
       "      <td>2.09</td>\n",
       "      <td>2.55</td>\n",
       "      <td>2.55</td>\n",
       "      <td>2.43</td>\n",
       "      <td>2.55</td>\n",
       "      <td>2.17</td>\n",
       "      <td>2.82</td>\n",
       "      <td>TEPAT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ERNA EKA RIYANTI</td>\n",
       "      <td>PEREMPUAN</td>\n",
       "      <td>MAHASISWA</td>\n",
       "      <td>25</td>\n",
       "      <td>BELUM MENIKAH</td>\n",
       "      <td>3.19</td>\n",
       "      <td>3.08</td>\n",
       "      <td>3.31</td>\n",
       "      <td>2.83</td>\n",
       "      <td>3.36</td>\n",
       "      <td>2.73</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.09</td>\n",
       "      <td>TEPAT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    NAMA JENIS KELAMIN STATUS MAHASISWA  UMUR   STATUS NIKAH  \\\n",
       "0                  UNAMA   LAKI - LAKI        MAHASISWA    24  BELUM MENIKAH   \n",
       "1  LEYLA TRIYANA PRATIWI     PEREMPUAN        MAHASISWA    26  BELUM MENIKAH   \n",
       "2  VERIS SOFIYAN PRAYOGA   LAKI - LAKI        MAHASISWA    29  BELUM MENIKAH   \n",
       "3   ADITYA AKBAR NUGRAHA   LAKI - LAKI        MAHASISWA    27  BELUM MENIKAH   \n",
       "4       ERNA EKA RIYANTI     PEREMPUAN        MAHASISWA    25  BELUM MENIKAH   \n",
       "\n",
       "   IPS 1  IPS 2  IPS 3  IPS 4  IPS 5  IPS 6  IPS 7  IPS 8  IPK   \\\n",
       "0   3.17   2.70   3.23   2.41   3.00   2.47   1.75   0.00  2.75   \n",
       "1   3.60   3.50   3.42   2.85   3.31   2.95   2.18    NaN  3.39   \n",
       "2   2.67   2.66   2.93   3.14   2.92   2.64   2.88   0.50  2.81   \n",
       "3   2.48   2.86   2.09   2.55   2.55   2.43   2.55   2.17  2.82   \n",
       "4   3.19   3.08   3.31   2.83   3.36   2.73   3.06   0.00  3.09   \n",
       "\n",
       "  STATUS KELULUSAN  \n",
       "0            TEPAT  \n",
       "1            TEPAT  \n",
       "2            TEPAT  \n",
       "3            TEPAT  \n",
       "4            TEPAT  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe = pandas.read_csv(\"datakelulusanmahasiswa-imbalance.csv\");\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Pre-Processing\n",
    "This part contains data pre-processing for the data. Data cleansing and preparation for the data so it could be processed later, and actually can be feed to the model as a tensor are applied here. \n",
    "\n",
    "- Drop \"NAMA\" column since it is not really matters.\n",
    "- Drop any row that contains NaN or null data. \n",
    "- Perform Hot-Top Encoding to \"JENIS KELAMIN\", \"STATUS MAHASISWA\", \"STATUS NIKAH\".\n",
    "- Convert \"STATUS KELULUSAN\", so that \"TEPAT\" converted to 1, otherwise goes 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['UMUR', 'IPS 1', 'IPS 2', 'IPS 3', 'IPS 4', 'IPS 5', 'IPS 6', 'IPS 7',\n",
       "       'IPS 8', 'IPK ', 'JENIS KELAMIN_LAKI - LAKI', 'JENIS KELAMIN_PEREMPUAN',\n",
       "       'STATUS MAHASISWA_BEKERJA', 'STATUS MAHASISWA_MAHASISWA',\n",
       "       'STATUS NIKAH_BELUM MENIKAH', 'STATUS KELULUSAN'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop name column\n",
    "dataframe = dataframe.drop(columns = [\"NAMA\"]);\n",
    "\n",
    "# Drop any row containing NaN or null data\n",
    "dataframe = dataframe.dropna();\n",
    "\n",
    "# Perform Hot-Top Encoding to all ordinal data.\n",
    "for i in [\"JENIS KELAMIN\", \"STATUS MAHASISWA\", \"STATUS NIKAH\"]:\n",
    "    hot_encoded = pandas.get_dummies(dataframe[i], prefix = i);\n",
    "    dataframe = pandas.concat([dataframe, hot_encoded], axis = 1);\n",
    "    dataframe = dataframe.drop(columns = [i]);\n",
    "\n",
    "# Convert labels to binary format.\n",
    "new_label = [];\n",
    "\n",
    "for i in dataframe[\"STATUS KELULUSAN\"]:\n",
    "    if(i == \"TEPAT\"):\n",
    "        new_label.append(1);\n",
    "    else:\n",
    "        new_label.append(0);\n",
    "\n",
    "dataframe = dataframe.drop(columns = [\"STATUS KELULUSAN\"]);\n",
    "dataframe[\"STATUS KELULUSAN\"] = new_label;\n",
    "\n",
    "# Print the column result of data pre-processing \n",
    "dataframe.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. \"Fixing\" the Imbalance problem\n",
    "\n",
    "Technically, when we face data imbalance, the problem are came from the data provider. But, since we can blame no one here, I will \"fix\" the imbalance problem anyway. The problem with the dataset is, that there are 136 rows of data with label of \"1\" while only 2 with label of \"0\". Well I can use SVM OneClass, but unfortunately, they want me to solve the problem with Decision Tree, so I cannot just drop the 2 negative clause data. So there are two treatments are applied to the data:\n",
    "\n",
    "- Label set: Perform the impossible by oversampling employing SMOTE by imblearn. \n",
    "This make new augmented data rows using statistical analysis performed within SMOTE, in which, in this case, are generating the data with label \"0\", as much as possible, so it is considered as \"balanced\" by ratio. \n",
    "\n",
    "- Feature set: Perform data normalization by performing data scaler to all features.  \n",
    "This treatment is to make every single features columns are standardized, by lowering the standard deviation, and make the value mean of 0. This will ease the model training phase. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total data before SMOTE:  138\n",
      "Total augmented data:  272\n",
      "Total after concatenated with augmented data:  410\n"
     ]
    }
   ],
   "source": [
    "# SMOTE operation\n",
    "\n",
    "print(\"Total data before SMOTE: \", len(dataframe[\"STATUS KELULUSAN\"]))\n",
    "\n",
    "oversample = SMOTE(random_state = 42, k_neighbors = 1);\n",
    "\n",
    "feature_resampled, label_resampled = oversample.fit_resample(\n",
    "    dataframe.drop(columns = [\"STATUS KELULUSAN\"]), \n",
    "    dataframe[\"STATUS KELULUSAN\"],\n",
    ");\n",
    "\n",
    "generated_data = len(label_resampled);\n",
    "\n",
    "feature_resampled[\"STATUS KELULUSAN\"] = label_resampled;\n",
    "\n",
    "dataframe = pandas.concat([dataframe, feature_resampled], ignore_index = True);\n",
    "\n",
    "print(\"Total augmented data: \", len(label_resampled));\n",
    "\n",
    "print(\"Total after concatenated with augmented data: \", len(dataframe));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STATUS KELULUSAN\n",
      "1    272\n",
      "0    138\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# SMOTE result\n",
    "print(dataframe[\"STATUS KELULUSAN\"].value_counts());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Scaler\n",
    "\n",
    "features = dataframe.drop(columns = [\"STATUS KELULUSAN\"]);\n",
    "\n",
    "scaler = StandardScaler();\n",
    "features = scaler.fit_transform(features);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Training Preparation\n",
    "\n",
    "This part contains the training preparation. This part conducts a train-test data splitting.\n",
    "\n",
    "| Data Split | Ratio |\n",
    "|---|---|\n",
    "| Train | 70% |\n",
    "| Test | 30% |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_train, feature_test, label_train, label_test = train_test_split(\n",
    "    features, \n",
    "    dataframe[\"STATUS KELULUSAN\"],\n",
    "    test_size = 0.3,\n",
    "    train_size = 0.7,\n",
    "    random_state = 42\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Training\n",
    "\n",
    "This part contains the model training process using sklearn.tree.DecisionTreeClassifier.\n",
    "The plan is, by employing GridSearchCV, what I do is basically experimenting with several parameters as below:\n",
    "\n",
    "| Parameter | Value being tested |\n",
    "|---|---|\n",
    "| `criterion` | `gini`, `entropy`, `log_loss` |\n",
    "| `splitter` | `best`, `random` |\n",
    "\n",
    "To decide which parameters are good, `roc_auc` is employed as its model evaluation. Also, within training process, I also do cross-validation with 5-Fold Cross Validation.\n",
    "\n",
    "See [this link regarding DecisionTreeClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html) for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters searched is {'criterion': 'gini', 'splitter': 'best'}\n"
     ]
    }
   ],
   "source": [
    "# Define parameters grid as mentioned above\n",
    "parameters = {\n",
    "    \"criterion\": [\"gini\", \"entropy\", \"log_loss\"],\n",
    "    \"splitter\": [\"best\", \"random\"]\n",
    "};\n",
    "\n",
    "model = DecisionTreeClassifier();\n",
    "\n",
    "# cv = 5 means 5-Fold Cross Validations\n",
    "searcher = GridSearchCV(model, param_grid = parameters, cv = 5, scoring = \"roc_auc\");\n",
    "\n",
    "searcher.fit(feature_train, label_train);\n",
    "\n",
    "best_parameters = searcher.best_params_;\n",
    "\n",
    "# This is where the best model for prediction is defined.\n",
    "best_model = searcher.best_estimator_;\n",
    "\n",
    "print(f\"The best parameters searched is {best_parameters}\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Evaluation\n",
    "\n",
    "This part contains the model evaluation. Basically, taking the best model from `best_model` variable aboves, and then testing it with `accuracy` and `roc_auc_score` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.983739837398374\n",
      "ROC AUC: 0.9880952380952381\n"
     ]
    }
   ],
   "source": [
    "prediction = best_model.predict(feature_test);\n",
    "\n",
    "accuracy = accuracy_score(label_test, prediction);\n",
    "roc_auc = roc_auc_score(label_test, prediction);\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\\nROC AUC: {roc_auc}\");"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uas",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
